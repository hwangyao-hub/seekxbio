#!/usr/bin/env python
"""
æ˜¾å¾®é•œè¡€ç»†èƒåˆ†æé¡¹ç›® - è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯ Codex å®ç°çš„åŠŸèƒ½
"""
from __future__ import annotations

import sys
import os
import tempfile
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(ROOT))


class TestResult:
    PASS = "âœ… PASS"
    FAIL = "âŒ FAIL"
    SKIP = "â­ï¸ SKIP"
    ERROR = "ğŸ’¥ ERROR"


def test_module_imports():
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    errors = []

    # æµ‹è¯• core æ¨¡å—å¯¼å…¥
    try:
        from core import infer_and_count
    except ImportError as e:
        errors.append(f"infer_and_count: {e}")

    try:
        from core import infer_batch
    except ImportError as e:
        errors.append(f"infer_batch: {e}")

    try:
        from core.train_core import train_yolov8_stream_with_process
    except ImportError as e:
        errors.append(f"train_yolov8_stream_with_process: {e}")

    if errors:
        print(f"{TestResult.FAIL}: æ¨¡å—å¯¼å…¥æµ‹è¯•")
        for err in errors:
            print(f"  - {err}")
        return False

    print(f"{TestResult.PASS}: æ¨¡å—å¯¼å…¥æµ‹è¯•")
    return True


def test_infer_batch_function_signature():
    """æµ‹è¯•æ‰¹é‡æ¨ç†å‡½æ•°ç­¾å"""
    from core import infer_batch
    import inspect

    sig = inspect.signature(infer_batch)
    params = list(sig.parameters.keys())

    required_params = ["weights", "source_dir", "output_dir"]
    optional_params = ["imgsz", "conf", "iou", "device", "label_mapping", "progress_callback"]

    missing = [p for p in required_params if p not in params]
    if missing:
        print(f"{TestResult.FAIL}: infer_batchç¼ºå°‘å‚æ•°: {missing}")
        return False

    print(f"{TestResult.PASS}: infer_batchå‡½æ•°ç­¾åæ­£ç¡®")
    return True


def test_train_stream_with_process_signature():
    """æµ‹è¯•è®­ç»ƒæµå‡½æ•°ç­¾å"""
    from core.train_core import train_yolov8_stream_with_process
    import inspect

    sig = inspect.signature(train_yolov8_stream_with_process)
    params = list(sig.parameters.keys())

    required_params = ["data_yaml"]
    if not all(p in params for p in required_params):
        print(f"{TestResult.FAIL}: train_yolov8_stream_with_processç¼ºå°‘å‚æ•°")
        return False

    # æ£€æŸ¥è¿”å›ç±»å‹æ³¨è§£
    annotations = train_yolov8_stream_with_process.__annotations__
    print(f"  è¿”å›ç±»å‹: {annotations.get('return', 'unknown')}")

    print(f"{TestResult.PASS}: train_yolov8_stream_with_processå‡½æ•°ç­¾åæ­£ç¡®")
    return True


def test_progress_parsing():
    """æµ‹è¯•è®­ç»ƒè¿›åº¦è§£æ"""
    try:
        # å°è¯•ä»app.pyå¯¼å…¥
        sys.path.insert(0, str(ROOT))
        from app import parse_training_progress
    except ImportError:
        # å¦‚æœapp.pyæ²¡æœ‰è¿™ä¸ªå‡½æ•°ï¼Œæ‰‹åŠ¨æµ‹è¯•é€»è¾‘
        import re

        def parse_training_progress(line: str):
            match = re.search(r"Epoch\s+(\d+)/(\d+)", line)
            if match:
                return int(match.group(1)), int(match.group(2))
            return None

    test_cases = [
        ("Epoch 1/100", (1, 100)),
        ("Epoch 15/100", (15, 100)),
        ("Epoch 100/100", (100, 100)),
        ("Some other log line", None),
        ("      Epoch 50/200      ", (50, 200)),
        ("", None),
        ("epoch 1/100", None),  # å°å†™ä¸åŒ¹é…
    ]

    failed = []
    for line, expected in test_cases:
        result = parse_training_progress(line)
        if result != expected:
            failed.append(f"'{line}': got {result}, expected {expected}")

    if failed:
        print(f"{TestResult.FAIL}: è¿›åº¦è§£ææµ‹è¯•")
        for f in failed:
            print(f"  - {f}")
        return False

    print(f"{TestResult.PASS}: è¿›åº¦è§£ææµ‹è¯• ({len(test_cases)} cases)")
    return True


def test_export_utils_exist():
    """æµ‹è¯•å¯¼å‡ºå·¥å…·æ¨¡å—å­˜åœ¨"""
    export_utils_path = ROOT / "core" / "export_utils.py"

    if not export_utils_path.exists():
        print(f"{TestResult.SKIP}: export_utils.py ä¸å­˜åœ¨ (å¯èƒ½æœªå®ç°)")
        return True

    try:
        from core.export_utils import export_coco_json, export_pascal_voc_xml
        print(f"{TestResult.PASS}: export_utilsæ¨¡å—å¯¼å…¥æˆåŠŸ")
        return True
    except ImportError as e:
        print(f"{TestResult.FAIL}: export_utilsæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False


def test_coco_export():
    """æµ‹è¯•COCO JSONå¯¼å‡º"""
    try:
        from core.export_utils import export_coco_json
    except ImportError:
        print(f"{TestResult.SKIP}: export_coco_json æœªå®ç°")
        return True

    import json
    from PIL import Image

    with tempfile.TemporaryDirectory() as tmpdir:
        # åˆ›å»ºæµ‹è¯•å›¾ç‰‡
        img_path = Path(tmpdir) / "test_img.png"
        Image.new("RGB", (640, 480), color="white").save(img_path)

        output_path = Path(tmpdir) / "coco_output.json"

        # æµ‹è¯•å¯¼å‡º
        all_detections = {
            "test_img.png": [
                {"class_id": 0, "bbox": [10, 20, 100, 150], "confidence": 0.95},
                {"class_id": 1, "bbox": [200, 200, 300, 350], "confidence": 0.88},
            ]
        }

        result = export_coco_json(
            image_paths=[str(img_path)],
            all_detections=all_detections,
            output_path=str(output_path),
            class_names={0: "RBC", 1: "WBC"},
        )

        # éªŒè¯è¾“å‡º
        assert output_path.exists(), "è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨"

        with open(output_path, encoding="utf-8") as f:
            coco = json.load(f)

        assert "images" in coco, "ç¼ºå°‘imageså­—æ®µ"
        assert "annotations" in coco, "ç¼ºå°‘annotationså­—æ®µ"
        assert "categories" in coco, "ç¼ºå°‘categorieså­—æ®µ"
        assert len(coco["images"]) == 1, f"imagesæ•°é‡é”™è¯¯: {len(coco['images'])}"
        assert len(coco["annotations"]) == 2, f"annotationsæ•°é‡é”™è¯¯: {len(coco['annotations'])}"

        # éªŒè¯bboxæ ¼å¼ (COCO: [x, y, width, height])
        ann = coco["annotations"][0]
        bbox = ann["bbox"]
        assert len(bbox) == 4, "bboxé•¿åº¦é”™è¯¯"
        # åŸå§‹: [10, 20, 100, 150] -> COCO: [10, 20, 90, 130]
        assert bbox[2] > 0 and bbox[3] > 0, "bboxå®½é«˜åº”ä¸ºæ­£æ•°"

    print(f"{TestResult.PASS}: COCO JSONå¯¼å‡ºæµ‹è¯•")
    return True


def test_voc_export():
    """æµ‹è¯•Pascal VOC XMLå¯¼å‡º"""
    try:
        from core.export_utils import export_pascal_voc_xml
    except ImportError:
        print(f"{TestResult.SKIP}: export_pascal_voc_xml æœªå®ç°")
        return True

    import xml.etree.ElementTree as ET
    from PIL import Image

    with tempfile.TemporaryDirectory() as tmpdir:
        # åˆ›å»ºæµ‹è¯•å›¾ç‰‡
        img_path = Path(tmpdir) / "test_img.png"
        Image.new("RGB", (640, 480), color="white").save(img_path)

        output_path = Path(tmpdir) / "voc_output.xml"

        detections = [
            {"class_id": 0, "bbox": [10, 20, 100, 150], "confidence": 0.95},
            {"class_id": 1, "bbox": [200, 200, 300, 350], "confidence": 0.88},
        ]

        result = export_pascal_voc_xml(
            image_path=str(img_path),
            detections=detections,
            output_path=str(output_path),
            class_names={0: "RBC", 1: "WBC"},
        )

        # éªŒè¯è¾“å‡º
        assert output_path.exists(), "è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨"

        tree = ET.parse(output_path)
        root = tree.getroot()

        assert root.tag == "annotation", f"æ ¹å…ƒç´ é”™è¯¯: {root.tag}"

        objects = root.findall("object")
        assert len(objects) == 2, f"objectæ•°é‡é”™è¯¯: {len(objects)}"

        # éªŒè¯ç¬¬ä¸€ä¸ªobject
        obj = objects[0]
        name = obj.find("name")
        assert name is not None, "ç¼ºå°‘nameå…ƒç´ "
        assert name.text == "RBC", f"nameé”™è¯¯: {name.text}"

        bndbox = obj.find("bndbox")
        assert bndbox is not None, "ç¼ºå°‘bndboxå…ƒç´ "
        assert bndbox.find("xmin") is not None, "ç¼ºå°‘xmin"
        assert bndbox.find("ymin") is not None, "ç¼ºå°‘ymin"
        assert bndbox.find("xmax") is not None, "ç¼ºå°‘xmax"
        assert bndbox.find("ymax") is not None, "ç¼ºå°‘ymax"

    print(f"{TestResult.PASS}: Pascal VOC XMLå¯¼å‡ºæµ‹è¯•")
    return True


def test_batch_inference_with_mock():
    """æµ‹è¯•æ‰¹é‡æ¨ç†ï¼ˆä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼‰"""
    from core import infer_batch

    with tempfile.TemporaryDirectory() as tmpdir:
        # åˆ›å»ºæµ‹è¯•å›¾ç‰‡ç›®å½•
        input_dir = Path(tmpdir) / "input"
        output_dir = Path(tmpdir) / "output"
        input_dir.mkdir()

        from PIL import Image
        for i in range(3):
            img = Image.new("RGB", (100, 100), color=(i * 80, i * 80, i * 80))
            img.save(input_dir / f"test_{i}.png")

        # ç”±äºæ²¡æœ‰çœŸå®æ¨¡å‹ï¼Œæµ‹è¯•ç©ºç›®å½•å¤„ç†
        empty_input = Path(tmpdir) / "empty"
        empty_input.mkdir()

        # æ£€æŸ¥æƒé‡æ–‡ä»¶
        weights = ROOT / "runs" / "detect" / "cells" / "weights" / "best.pt"
        if not weights.exists():
            # å°è¯•æŸ¥æ‰¾å…¶ä»–æƒé‡
            alt_weights = list(ROOT.rglob("*.pt"))
            if alt_weights:
                weights = alt_weights[0]
                print(f"  ä½¿ç”¨æ›¿ä»£æƒé‡: {weights}")
            else:
                print(f"{TestResult.SKIP}: æ— å¯ç”¨æ¨¡å‹æƒé‡")
                return True

        # æµ‹è¯•ç©ºç›®å½•
        results = infer_batch(
            weights=str(weights),
            source_dir=str(empty_input),
            output_dir=str(output_dir / "empty_test"),
        )

        assert results["total_images"] == 0, "ç©ºç›®å½•åº”è¿”å›0å¼ å›¾ç‰‡"

        print(f"{TestResult.PASS}: æ‰¹é‡æ¨ç†åŸºç¡€æµ‹è¯•")
        return True


def test_gradio_batch_ui_elements():
    """æµ‹è¯•Gradioç•Œé¢ä¸­çš„æ‰¹é‡æ¨ç†å…ƒç´ """
    app_path = ROOT / "app.py"

    if not app_path.exists():
        print(f"{TestResult.SKIP}: app.pyä¸å­˜åœ¨")
        return True

    content = app_path.read_text(encoding="utf-8")

    required_elements = [
        "æ‰¹é‡æ¨ç†",
        "run_batch_inference",
        "batch_input_dir",
        "batch_output_dir",
    ]

    missing = [elem for elem in required_elements if elem not in content]

    if missing:
        print(f"{TestResult.FAIL}: Gradioç•Œé¢ç¼ºå°‘æ‰¹é‡æ¨ç†å…ƒç´ : {missing}")
        return False

    print(f"{TestResult.PASS}: Gradioæ‰¹é‡æ¨ç†UIå…ƒç´ å­˜åœ¨")
    return True


def test_desktop_batch_ui_elements():
    """æµ‹è¯•Desktop UIä¸­çš„æ‰¹é‡æ¨ç†å…ƒç´ """
    inference_page = ROOT / "ui" / "pages" / "inference_page.py"

    if not inference_page.exists():
        print(f"{TestResult.SKIP}: inference_page.pyä¸å­˜åœ¨")
        return True

    content = inference_page.read_text(encoding="utf-8")

    required_elements = [
        "BatchInferenceWorker",
        "batch_input",
        "batch_output",
        "run_batch_inference",
    ]

    missing = [elem for elem in required_elements if elem not in content]

    if missing:
        print(f"{TestResult.FAIL}: Desktop UIç¼ºå°‘æ‰¹é‡æ¨ç†å…ƒç´ : {missing}")
        return False

    print(f"{TestResult.PASS}: Desktopæ‰¹é‡æ¨ç†UIå…ƒç´ å­˜åœ¨")
    return True


def test_training_process_control():
    """æµ‹è¯•è®­ç»ƒè¿›ç¨‹æ§åˆ¶å…ƒç´ """
    app_path = ROOT / "app.py"

    if not app_path.exists():
        print(f"{TestResult.SKIP}: app.pyä¸å­˜åœ¨")
        return True

    content = app_path.read_text(encoding="utf-8")

    required_elements = [
        "training_process",
        "stop_training",
        "killpg" if os.name != "nt" else "terminate",  # Unixç”¨killpgï¼ŒWindowsç”¨terminate
    ]

    # è‡³å°‘éœ€è¦æœ‰è¿›ç¨‹æ§åˆ¶é€»è¾‘
    has_process_control = "training_process" in content and "stop_training" in content

    if not has_process_control:
        print(f"{TestResult.FAIL}: ç¼ºå°‘è®­ç»ƒè¿›ç¨‹æ§åˆ¶é€»è¾‘")
        return False

    print(f"{TestResult.PASS}: è®­ç»ƒè¿›ç¨‹æ§åˆ¶é€»è¾‘å­˜åœ¨")
    return True


def test_annotation_undo_redo():
    """æµ‹è¯•æ ‡æ³¨å·¥å…·æ’¤é”€/é‡åšå…ƒç´ """
    annotation_tool = ROOT / "ui" / "annotation_tool.py"

    if not annotation_tool.exists():
        print(f"{TestResult.SKIP}: annotation_tool.pyä¸å­˜åœ¨")
        return True

    content = annotation_tool.read_text(encoding="utf-8")

    undo_elements = ["undo", "_history"]
    redo_elements = ["redo", "_redo_stack"]

    has_undo = any(elem in content for elem in undo_elements)
    has_redo = any(elem in content for elem in redo_elements)

    if not has_undo:
        print(f"{TestResult.FAIL}: æ ‡æ³¨å·¥å…·ç¼ºå°‘æ’¤é”€åŠŸèƒ½")
        return False

    if not has_redo:
        print(f"{TestResult.FAIL}: æ ‡æ³¨å·¥å…·ç¼ºå°‘é‡åšåŠŸèƒ½")
        return False

    print(f"{TestResult.PASS}: æ ‡æ³¨å·¥å…·æ’¤é”€/é‡åšåŠŸèƒ½å­˜åœ¨")
    return True


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 60)
    print("æ˜¾å¾®é•œè¡€ç»†èƒåˆ†æé¡¹ç›® - è‡ªåŠ¨åŒ–æµ‹è¯•")
    print("=" * 60)
    print()

    tests = [
        ("æ¨¡å—å¯¼å…¥", test_module_imports),
        ("infer_batchå‡½æ•°ç­¾å", test_infer_batch_function_signature),
        ("train_stream_with_processç­¾å", test_train_stream_with_process_signature),
        ("è®­ç»ƒè¿›åº¦è§£æ", test_progress_parsing),
        ("å¯¼å‡ºå·¥å…·æ¨¡å—", test_export_utils_exist),
        ("COCO JSONå¯¼å‡º", test_coco_export),
        ("Pascal VOCå¯¼å‡º", test_voc_export),
        ("æ‰¹é‡æ¨ç†åŸºç¡€åŠŸèƒ½", test_batch_inference_with_mock),
        ("Gradioæ‰¹é‡æ¨ç†UI", test_gradio_batch_ui_elements),
        ("Desktopæ‰¹é‡æ¨ç†UI", test_desktop_batch_ui_elements),
        ("è®­ç»ƒè¿›ç¨‹æ§åˆ¶", test_training_process_control),
        ("æ ‡æ³¨å·¥å…·æ’¤é”€/é‡åš", test_annotation_undo_redo),
    ]

    results = {"pass": 0, "fail": 0, "skip": 0, "error": 0}

    for name, test_func in tests:
        print(f"\n[{name}]")
        try:
            success = test_func()
            if success:
                results["pass"] += 1
            else:
                results["fail"] += 1
        except AssertionError as e:
            print(f"{TestResult.FAIL}: {e}")
            results["fail"] += 1
        except Exception as e:
            print(f"{TestResult.ERROR}: {type(e).__name__}: {e}")
            results["error"] += 1

    print()
    print("=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    print(f"âœ… é€šè¿‡: {results['pass']}")
    print(f"âŒ å¤±è´¥: {results['fail']}")
    print(f"â­ï¸ è·³è¿‡: {results['skip']}")
    print(f"ğŸ’¥ é”™è¯¯: {results['error']}")
    print()

    total = results["pass"] + results["fail"]
    if total > 0:
        pass_rate = results["pass"] / total * 100
        print(f"é€šè¿‡ç‡: {pass_rate:.1f}%")

    return results["fail"] == 0 and results["error"] == 0


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
